{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP7VvLpQM/MrlD6Mpr5FCtu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"yFqMuNYkN4ns"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","import matplotlib.pyplot as plt\n","\n","# Define the generator network\n","def build_generator():\n","    model = models.Sequential()\n","    model.add(layers.Dense(256, input_dim=100, activation='relu'))\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.Dense(512, activation='relu'))\n","    model.add(layers.BatchNormalization())\n","    model.add(layers.Dense(784, activation='sigmoid'))\n","    model.add(layers.Reshape((28, 28, 1)))\n","    return model\n","\n","# Define the discriminator network\n","def build_discriminator():\n","    model = models.Sequential()\n","    model.add(layers.Flatten(input_shape=(28, 28, 1)))\n","    model.add(layers.Dense(512, activation='relu'))\n","    model.add(layers.Dense(256, activation='relu'))\n","    model.add(layers.Dense(1, activation='sigmoid'))\n","    return model\n","\n","# Create the generator and discriminator\n","generator = build_generator()\n","discriminator = build_discriminator()\n","\n","# Compile the discriminator\n","discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# The generator takes random noise as input and generates images\n","z = layers.Input(shape=(100,))\n","img = generator(z)\n","\n","# The discriminator will not be trained during the combined GAN model training\n","discriminator.trainable = False\n","\n","# The discriminator takes real images and generated images as input and classifies them\n","validity = discriminator(img)\n","\n","# The combined GAN model (stacked generator and discriminator)\n","combined = models.Model(z, validity)\n","combined.compile(optimizer='adam', loss='binary_crossentropy')\n","\n","# Load and preprocess a dataset (e.g., MNIST)\n","(x_train, _), (_, _) = tf.keras.datasets.mnist.load_data()\n","x_train = x_train / 255.0\n","x_train = np.expand_dims(x_train, axis=-1)\n","\n","# Training parameters\n","batch_size = 64\n","epochs = 10000\n","sample_interval = 1000\n","\n","# Training the GAN\n","for epoch in range(epochs):\n","    # Train the discriminator\n","    idx = np.random.randint(0, x_train.shape[0], batch_size)\n","    real_imgs = x_train[idx]\n","    fake_imgs = generator.predict(np.random.rand(batch_size, 100))\n","    d_loss_real = discriminator.train_on_batch(real_imgs, np.ones((batch_size, 1)))\n","    d_loss_fake = discriminator.train_on_batch(fake_imgs, np.zeros((batch_size, 1)))\n","    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","    # Train the generator\n","    z = np.random.rand(batch_size, 100)\n","    g_loss = combined.train_on_batch(z, np.ones((batch_size, 1)))\n","\n","    # Print progress\n","    if epoch % 100 == 0:\n","        print(f\"Epoch {epoch}, D Loss: {d_loss[0]}, G Loss: {g_loss}\")\n","\n","    # Save generated images at specified intervals\n","    if epoch % sample_interval == 0:\n","        samples = generator.predict(np.random.rand(16, 100))\n","        samples = 0.5 * samples + 0.5  # Rescale values from -1 to 1 to 0 to 1\n","        fig, axs = plt.subplots(4, 4)\n","        cnt = 0\n","        for i in range(4):\n","            for j in range(4):\n","                axs[i, j].imshow(samples[cnt, :, :, 0], cmap='gray')\n","                axs[i, j].axis('off')\n","                cnt += 1\n","        plt.show()\n"]}]}